
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Procesamiento de Lenguaje Natural (NLP) &#8212; Introducción a la Ciencia de Datos</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Ejercicio misceláneo: NLP, Web Scrapping" href="../4.%20Segundo%20parcial%20Ejercicio%20tema%201%2C%202%20y%203/Prueba%20dos%20resulta%20por%20el%20profesor.html" />
    <link rel="prev" title="Ejercicio: Web Scrapping para extraer información de un artículo" href="../2.%20Web%20Scraping/Ejercicio_NUSO_web_scrappng.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introducción a la Ciencia de Datos</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Welcome to your Jupyter Book
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../1.%20Pandas/pandas.html">
   Explorando y analizando DataFrames con Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2.%20Web%20Scraping/web_scraping.html">
   Web Scraping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2.%20Web%20Scraping/Ejercicio_NUSO_web_scrappng.html">
   Ejercicio: Web Scrapping para extraer información de un artículo
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Procesamiento de Lenguaje Natural (
   <em>
    NLP
   </em>
   )
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../4.%20Segundo%20parcial%20Ejercicio%20tema%201%2C%202%20y%203/Prueba%20dos%20resulta%20por%20el%20profesor.html">
   Ejercicio misceláneo: NLP, Web Scrapping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../4.%20Segundo%20parcial%20Ejercicio%20tema%201%2C%202%20y%203/Segundo%20examen%20parcial.html">
   Ejercicio misceláneo: NLP, Web Scrapping (otra resolución)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.%20Analisis%20Exploratorio/5.1%20Introduccion%20al%20Analisis%20Exploratorio%20de%20Datos.html">
   Análisis exploratorio de datos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.%20Analisis%20Exploratorio/5.2%20An%C3%A1lisis%20exploratorio%20de%20datos%20unidimensionales.html">
   Análisis unidimensional
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.%20Analisis%20Exploratorio/5.3%20Analisis%20exploratorio%20de%20datos%20multidimensionales.html">
   Análisis exploratorio de datos multivariable
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.%20Analisis%20Exploratorio/Ejercicio%20parte%201.html">
   Ejercicio análisi exploratorio parte 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5.%20Analisis%20Exploratorio/Ejercicio%20parte%202.html">
   Ejercicio análisi exploratorio parte 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../6.%20Feature%20Engineering/data%20reshaping.html">
   Data Reshaping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../6.%20Feature%20Engineering/feature%20engineering.html">
   Feature engineering (preparación de variables)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../6.%20Feature%20Engineering/Ejercicio%20feature%20engineering.html">
   Ejercicio Feature Engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../7.%20Tercer%20parcial%20Ejercicio%20tema%205%20y%206/pec03.html">
   Ejercicio misceláneo: Análisis exploratorio y Feature Engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../8.%20Feature%20Selection/03_feature-selection.html">
   Feature selection (selección de variables)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10.%20Modelos%20predictivos/01_fundamentos.html">
   Aprendizaje Automático (Machine Learning)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10.%20Modelos%20predictivos/02_scikit-learn.html">
   Scikit-learn: basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10.%20Modelos%20predictivos/03_regresion-logistica.html">
   Regresión logística
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10.%20Modelos%20predictivos/04-arboles-de-decision.html">
   Arboles de decisión: Introducción
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10.%20Modelos%20predictivos/Ejercicio%20regresi%C3%B3n%20log%C3%ADstica.html">
   Ejercicio Regresión Logística
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../11.%20Cuarto%20parcial/pec04.html">
   Ejercicio misceláneo: Feature Selection, Modelos predictivos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../12.%20Arboles%20de%20decision/04-arboles-de-decision-python.html">
   Arboles de decisión: Hiperparámetros, Random Forest y Optimización de Parámetros
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../13.%20Guardar%20y%20utilizar%20una%20API/Guardar%20y%20desplegar%20un%20clasificador.html">
   Guardar y deployar un modelo predictivo
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/Notebooks/3. Procesamiento del Lenguaje Natural/nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/jordanmontt/introduccion-ciencia-de-datos"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/jordanmontt/introduccion-ciencia-de-datos/issues/new?title=Issue%20on%20page%20%2FNotebooks/3. Procesamiento del Lenguaje Natural/nlp.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/jordanmontt/introduccion-ciencia-de-datos/master?urlpath=tree/docs/Notebooks/3. Procesamiento del Lenguaje Natural/nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Procesamiento de Lenguaje Natural (
   <em>
    NLP
   </em>
   )
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algunas-aplicaciones-de-nlp">
     Algunas aplicaciones de
     <em>
      NLP
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vocabulario-del-problema">
   Vocabulario del problema
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenizacion">
     Tokenización
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tokenizacion-a-nivel-oraciones">
       Tokenización a nivel oraciones
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tokenizacion-a-nivel-de-palabras">
       Tokenización a nivel de palabras.
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quitar-palabras-de-parada">
     Quitar palabras de parada
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#otras-tareas-de-limpieza-que-se-pueden-considerar">
     Otras tareas de limpieza que se pueden considerar
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lematizacion">
     Lematización
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#identificar-n-gramas">
     Identificar n-gramas
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#desambiguacion-linguistica-word-sense-disambiguation">
     Desambiguación lingüística (
     <em>
      Word Sense Disambiguation
     </em>
     )
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etiquetado-gramatical-part-of-speech-tagging">
     Etiquetado gramatical (
     <em>
      Part of Speech Tagging
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#representacion-del-texto">
   Representación del texto
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-hot-encoding-tuplas-de-palabras">
     One-hot encoding (tuplas de palabras)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tf-idf-term-frequency-inverse-document-frequency">
     TF-IDF (Term frequency, inverse document frequency)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tf-term-frequency">
       TF  (Term Frequency)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#idf-inverse-document-frequency">
       IDF  (Inverse Document Frequency)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#word-embeddings">
     Word embeddings
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Procesamiento de Lenguaje Natural (NLP)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Procesamiento de Lenguaje Natural (
   <em>
    NLP
   </em>
   )
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algunas-aplicaciones-de-nlp">
     Algunas aplicaciones de
     <em>
      NLP
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vocabulario-del-problema">
   Vocabulario del problema
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenizacion">
     Tokenización
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tokenizacion-a-nivel-oraciones">
       Tokenización a nivel oraciones
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tokenizacion-a-nivel-de-palabras">
       Tokenización a nivel de palabras.
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quitar-palabras-de-parada">
     Quitar palabras de parada
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#otras-tareas-de-limpieza-que-se-pueden-considerar">
     Otras tareas de limpieza que se pueden considerar
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lematizacion">
     Lematización
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#identificar-n-gramas">
     Identificar n-gramas
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#desambiguacion-linguistica-word-sense-disambiguation">
     Desambiguación lingüística (
     <em>
      Word Sense Disambiguation
     </em>
     )
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etiquetado-gramatical-part-of-speech-tagging">
     Etiquetado gramatical (
     <em>
      Part of Speech Tagging
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#representacion-del-texto">
   Representación del texto
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-hot-encoding-tuplas-de-palabras">
     One-hot encoding (tuplas de palabras)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tf-idf-term-frequency-inverse-document-frequency">
     TF-IDF (Term frequency, inverse document frequency)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tf-term-frequency">
       TF  (Term Frequency)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#idf-inverse-document-frequency">
       IDF  (Inverse Document Frequency)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#word-embeddings">
     Word embeddings
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="procesamiento-de-lenguaje-natural-nlp">
<h1>Procesamiento de Lenguaje Natural (<em>NLP</em>)<a class="headerlink" href="#procesamiento-de-lenguaje-natural-nlp" title="Permalink to this headline">¶</a></h1>
<p><strong><a class="reference external" href="https://es.wikipedia.org/wiki/Procesamiento_de_lenguajes_naturales">NLP</a></strong> es un campo de las ciencias de la computación, inteligencia artificial y lingüística que estudia las interacciones entre las computadoras y el lenguaje humano. Se ocupa de la formulación e investigación de mecanismos eficaces computacionalmente para la comunicación entre personas y máquinas por medio del lenguaje natural. En poca palabras, hacer que la computadora pueden entender y responder en lenguage natural.</p>
<div class="section" id="algunas-aplicaciones-de-nlp">
<h2>Algunas aplicaciones de <em>NLP</em><a class="headerlink" href="#algunas-aplicaciones-de-nlp" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Extracción de palabras clave (<em>Keyword extraction</em>): identificación automática de términos importantes que mejor describan el tema de un documento.</p></li>
<li><p>Extracción de entidades (<em>Named-Entity Recognition</em>): busca localizar en el texto entidades como personas, organizaciones, lugares, expresiones de tiempo y cantidades.</p></li>
<li><p>Clasificación de texto: es asignar una categoría a un documento, esto sirve para la detección de <em>spam</em>, análisis de sentimientos, priorización de contenido, etc.</p></li>
<li><p>Resumen automático (<em>Text summarization</em>): encontrar las oraciones más informativas en un documento.</p></li>
<li><p><em>Topic modeling</em>: es un tipo de modelo estadístico para descubrir los “topics” abstractos que ocurren en una colección de documentos. Descubre semanticas ocultas en un cuerpo de texto. Encuentra el tema en un conjunto de documentos.</p></li>
<li><p>Traducción automática (<em>Machine translation</em>): el uso de <em>software</em> para traducir texto o habla de un lenguaje natural a otro.</p></li>
</ul>
<ol class="simple">
<li><p><a class="reference external" href="#1">Vocabulario del problema</a></p>
<ol class="simple">
<li><p><a class="reference external" href="#2">Tokenización</a></p></li>
<li><p><a class="reference external" href="#3">Quitar palabras de parada</a></p></li>
<li><p><a class="reference external" href="#4">Otras tareas de limpieza que se pueden considerar</a></p></li>
<li><p><a class="reference external" href="#5">Lematización</a></p></li>
<li><p><a class="reference external" href="#6">Identificaciín de N-gramas</a></p></li>
<li><p><a class="reference external" href="#7">Desambiguación lingüística (<em>Word Sense Disambiguation</em>)</a></p></li>
<li><p><a class="reference external" href="#8">Etiquetado gramatical (<em>Part of Speech Tagging</em>)</a></p></li>
</ol>
</li>
<li><p><a class="reference external" href="#9">Representacion del texto</a></p>
<ol class="simple">
<li><p><a class="reference external" href="#10">One-hot encoding (tuplas de palabras)</a></p></li>
<li><p><a class="reference external" href="#11"> TF-IDF (Term frequency, inverse document frequency)</a></p></li>
<li><p><a class="reference external" href="#12"><em>Word embeddings</em></a></p></li>
</ol>
</li>
</ol>
<p><a id="1"></a></p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="vocabulario-del-problema">
<h1>Vocabulario del problema<a class="headerlink" href="#vocabulario-del-problema" title="Permalink to this headline">¶</a></h1>
<p>En un proyecto de <em>NLP</em> se trabajan con colecciones de “documentos”. Cada documento en un fragmento de texto que se debe procesar de manera individual (clasificar, representar, etc). Algunos ejemplos de documentos son: tweets, revisiones, artículos, libros, etc. El conjunto de todas la palabras que aparecen en todos los documentos constituye el <strong>vocabulario del problema</strong>. En muchos casos el tamaño del problema puede reducir el desempeño de la solución y es necesario reducirlo.</p>
<p>Los elementos en el vocabulario se conocen como <em>tokens</em>; dependiendo del problema y las decisiones de diseño podrían no ser necesariamente una palabra. Por ejemplo, los emoticones, lemas o palabras compuestas.</p>
<p>En este <em>notebook</em> se muestra como realizar una de las tareas más comunes que ayudan a reducir el tamaño del vocabulario: la eliminación de palabras de parada (<em>stop words</em>).</p>
<p><a id="2"></a></p>
<div class="section" id="tokenizacion">
<h2>Tokenización<a class="headerlink" href="#tokenizacion" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html">Tokenización</a> es el proceso de separar el texto en piezas llamadas <em>tokens</em>. Es la primera tarea/proceso en cualquier proyecto <em>NLP</em>. Es fundamental realizarla bien para no afectar la calidad de los datos de entrada en las etapas siguientes. Se recomienda usar un <em>tokenizer</em> reconocido y evitar intentar programar uno desde cero.</p>
<p><img alt="Tokenización" src="../../_images/01-tokenization.png" /></p>
<p>A continuación, se muestra un ejemplo de tokenización sobre esta <a class="reference external" href="https://www.lostiempos.com/deportes/multideportivo/20200115/olympic-albert-einstein-ucb-lpz-van-paso-firme-liga-superior">noticia</a>. Primero debes cargar la noticia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">texto_noticia</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Los clubes cochabambinos de Olympic, Albert Einstein y el paceño Universidad Católica Boliviana (UCB) avanzan a paso firme y constante rumbo a la corona en la Liga Superior de voleibol, rama femenina, que se desarrolla en el coliseo Julio Borelli Vitterito de La Paz, luego de cosechar sendas victorias la noche de este martes. El ganador será representante de Bolivia en la Liga Sudamericana de Clubes 2020.</span>

<span class="s2">El campeón defensor del título, Olympic, superó 3-0  a su verdugo de la final de la edición 2017, el también cochabambino San Simón. La victoria para las olympiquistas fue con sets de 25-14, 25-13 y 25-18.&quot;&quot;&quot;</span>
<span class="n">texto_noticia</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Los clubes cochabambinos de Olympic, Albert Einstein y el paceño Universidad Católica Boliviana (UCB) avanzan a paso firme y constante rumbo a la corona en la Liga Superior de voleibol, rama femenina, que se desarrolla en el coliseo Julio Borelli Vitterito de La Paz, luego de cosechar sendas victorias la noche de este martes. El ganador será representante de Bolivia en la Liga Sudamericana de Clubes 2020.\n\nEl campeón defensor del título, Olympic, superó 3-0  a su verdugo de la final de la edición 2017, el también cochabambino San Simón. La victoria para las olympiquistas fue con sets de 25-14, 25-13 y 25-18.&#39;
</pre></div>
</div>
</div>
</div>
<div class="section" id="tokenizacion-a-nivel-oraciones">
<h3>Tokenización a nivel oraciones<a class="headerlink" href="#tokenizacion-a-nivel-oraciones" title="Permalink to this headline">¶</a></h3>
<p>La función <font color="gray">sent_tokenize(…)</font> de <font color="gray">nltk.tokenize</font> es el tokenizador a nivel de oraciones. Si tienes problemas importando la librería <a class="reference external" href="https://www.nltk.org/api/nltk.tokenize.html"><em>nltk</em></a>, ejecuta <font color="gray">nltk.download(‘punkt’)</font> desde la consola de Python para descargar la librería.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">oraciones_noticia</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">texto_noticia</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s1">&#39;spanish&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Número total de oraciones de la noticia: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">oraciones_noticia</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Texto de la oracion 1: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">oraciones_noticia</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Input</span> <span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">nltk</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">oraciones_noticia</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">texto_noticia</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s1">&#39;spanish&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Número total de oraciones de la noticia: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">oraciones_noticia</span><span class="p">)))</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;nltk&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="tokenizacion-a-nivel-de-palabras">
<h3>Tokenización a nivel de palabras.<a class="headerlink" href="#tokenizacion-a-nivel-de-palabras" title="Permalink to this headline">¶</a></h3>
<p>La función <font color="gray">nltk.word_tokenize(…)</font> es el tokenizador a nivel de palabras recomendado por <em>NLTK</em>. El resultado de esta función es una lista con todas las palabras de la noticia. Internamente usa una instancia de la clase <font color="gray">TreebankWordTokenizer</font> (en la versión más reciente)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">palabras_noticia</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">texto_noticia</span><span class="p">)</span>
<span class="n">palabras_noticia</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Los&#39;,
 &#39;clubes&#39;,
 &#39;cochabambinos&#39;,
 &#39;de&#39;,
 &#39;Olympic&#39;,
 &#39;,&#39;,
 &#39;Albert&#39;,
 &#39;Einstein&#39;,
 &#39;y&#39;,
 &#39;el&#39;,
 &#39;paceño&#39;,
 &#39;Universidad&#39;,
 &#39;Católica&#39;,
 &#39;Boliviana&#39;,
 &#39;(&#39;,
 &#39;UCB&#39;,
 &#39;)&#39;,
 &#39;avanzan&#39;,
 &#39;a&#39;,
 &#39;paso&#39;,
 &#39;firme&#39;,
 &#39;y&#39;,
 &#39;constante&#39;,
 &#39;rumbo&#39;,
 &#39;a&#39;,
 &#39;la&#39;,
 &#39;corona&#39;,
 &#39;en&#39;,
 &#39;la&#39;,
 &#39;Liga&#39;,
 &#39;Superior&#39;,
 &#39;de&#39;,
 &#39;voleibol&#39;,
 &#39;,&#39;,
 &#39;rama&#39;,
 &#39;femenina&#39;,
 &#39;,&#39;,
 &#39;que&#39;,
 &#39;se&#39;,
 &#39;desarrolla&#39;,
 &#39;en&#39;,
 &#39;el&#39;,
 &#39;coliseo&#39;,
 &#39;Julio&#39;,
 &#39;Borelli&#39;,
 &#39;Vitterito&#39;,
 &#39;de&#39;,
 &#39;La&#39;,
 &#39;Paz&#39;,
 &#39;,&#39;,
 &#39;luego&#39;,
 &#39;de&#39;,
 &#39;cosechar&#39;,
 &#39;sendas&#39;,
 &#39;victorias&#39;,
 &#39;la&#39;,
 &#39;noche&#39;,
 &#39;de&#39;,
 &#39;este&#39;,
 &#39;martes&#39;,
 &#39;.&#39;,
 &#39;El&#39;,
 &#39;ganador&#39;,
 &#39;será&#39;,
 &#39;representante&#39;,
 &#39;de&#39;,
 &#39;Bolivia&#39;,
 &#39;en&#39;,
 &#39;la&#39;,
 &#39;Liga&#39;,
 &#39;Sudamericana&#39;,
 &#39;de&#39;,
 &#39;Clubes&#39;,
 &#39;2020&#39;,
 &#39;.&#39;,
 &#39;El&#39;,
 &#39;campeón&#39;,
 &#39;defensor&#39;,
 &#39;del&#39;,
 &#39;título&#39;,
 &#39;,&#39;,
 &#39;Olympic&#39;,
 &#39;,&#39;,
 &#39;superó&#39;,
 &#39;3-0&#39;,
 &#39;a&#39;,
 &#39;su&#39;,
 &#39;verdugo&#39;,
 &#39;de&#39;,
 &#39;la&#39;,
 &#39;final&#39;,
 &#39;de&#39;,
 &#39;la&#39;,
 &#39;edición&#39;,
 &#39;2017&#39;,
 &#39;,&#39;,
 &#39;el&#39;,
 &#39;también&#39;,
 &#39;cochabambino&#39;,
 &#39;San&#39;,
 &#39;Simón&#39;,
 &#39;.&#39;,
 &#39;La&#39;,
 &#39;victoria&#39;,
 &#39;para&#39;,
 &#39;las&#39;,
 &#39;olympiquistas&#39;,
 &#39;fue&#39;,
 &#39;con&#39;,
 &#39;sets&#39;,
 &#39;de&#39;,
 &#39;25-14&#39;,
 &#39;,&#39;,
 &#39;25-13&#39;,
 &#39;y&#39;,
 &#39;25-18&#39;,
 &#39;.&#39;]
</pre></div>
</div>
</div>
</div>
<p>Debes saber que <font color="gray">word_tokenize</font>, no es la única función que permite realizar este trabajo. Puedes utilizar también <font color="gray">casual_tokenize</font>. Encuentra la diferencia =)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">casual</span><span class="o">.</span><span class="n">casual_tokenize</span><span class="p">(</span><span class="s2">&quot;Que buena pelicula. Gracias por invitarme :)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Que&#39;, &#39;buena&#39;, &#39;pelicula&#39;, &#39;.&#39;, &#39;Gracias&#39;, &#39;por&#39;, &#39;invitarme&#39;, &#39;:)&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="s2">&quot;Que buena pelicula. Gracias por invitarme :)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Que&#39;, &#39;buena&#39;, &#39;pelicula&#39;, &#39;.&#39;, &#39;Gracias&#39;, &#39;por&#39;, &#39;invitarme&#39;, &#39;:&#39;, &#39;)&#39;]
</pre></div>
</div>
</div>
</div>
<p><a id="3"></a></p>
</div>
</div>
<div class="section" id="quitar-palabras-de-parada">
<h2>Quitar palabras de parada<a class="headerlink" href="#quitar-palabras-de-parada" title="Permalink to this headline">¶</a></h2>
<p>Dependiendo del lenguaje existen palabras que tienden a repetirse mucho más que otras, estas generalmente son los artículos, las preposiciones, y las conjunciones. Estas palabras suelen ser perjudiciales al momento de analizar el texto porque no aportan información relevante, es por eso que se deben quitar las palabras de parada del vocabulario del problema. Tener en cuenta que NO hay una lista universal y exhaustiva de estas palabras. Cada lenguage e incluso tipo de problema puede tener su propia lista de palabras de parada.</p>
<p><img alt="remove_stopwords" src="../../_images/02-remove_stopwords.png" /></p>
<p>Puesto que estas listas pueden variar dependiendo de la librería o incluso entre versiones de la misma librería, incluir este paso puede dificultar la reproducción de los resultados en otros entornos. Veremos más adelante que hay otros mecanismos para lidiar con este tipo de palabras (<em>TF</em>, <em>IDF</em>).</p>
<p>Ten en cuenta tambien que quitar alguna palabra de parada como los artículos podría cambiar completamente el significado de algunas palabras compuestas.</p>
<p>Por ejemplo: “La Paz” nombre de un departamento de Bolivia se convierte en -&gt; “Paz” y pierde el sentido.</p>
<p>Si deseas aprender más, ingresa en los siguientes enlaces:</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://www.pythond.com/21143/como-eliminar-las-palabras-de-parada-usando-nltk-o-python.html">Cómo eliminar las palabras de parada usando nltk o python</a></strong></p></li>
<li><p><strong><a class="reference external" href="https://pypi.org/project/stop-words/">Proyecto stop-words</a></strong></p></li>
<li><p><strong><a class="reference external" href="https://github.com/xiamx/node-nltk-stopwords/blob/master/data/stopwords/spanish">Proyecto node-nltk-stopwords</a></strong></p></li>
<li><p><strong><a class="reference external" href="https://www.ranks.nl/stopwords">Stopwords &#64; ranks.nl</a></strong></p></li>
</ul>
<p>Si tienes problemas importando la libreria <em>nltk</em>, ejecuta este comando <font color="gray">nltk.download(‘stopwords’)</font>. En el ejemplo se puede ver la lista de palabras de parada que nos ofrece la libreria <font color="gray">nltk.corpus</font></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;spanish&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;de&#39;,
 &#39;la&#39;,
 &#39;que&#39;,
 &#39;el&#39;,
 &#39;en&#39;,
 &#39;y&#39;,
 &#39;a&#39;,
 &#39;los&#39;,
 &#39;del&#39;,
 &#39;se&#39;,
 &#39;las&#39;,
 &#39;por&#39;,
 &#39;un&#39;,
 &#39;para&#39;,
 &#39;con&#39;,
 &#39;no&#39;,
 &#39;una&#39;,
 &#39;su&#39;,
 &#39;al&#39;,
 &#39;lo&#39;,
 &#39;como&#39;,
 &#39;más&#39;,
 &#39;pero&#39;,
 &#39;sus&#39;,
 &#39;le&#39;,
 &#39;ya&#39;,
 &#39;o&#39;,
 &#39;este&#39;,
 &#39;sí&#39;,
 &#39;porque&#39;,
 &#39;esta&#39;,
 &#39;entre&#39;,
 &#39;cuando&#39;,
 &#39;muy&#39;,
 &#39;sin&#39;,
 &#39;sobre&#39;,
 &#39;también&#39;,
 &#39;me&#39;,
 &#39;hasta&#39;,
 &#39;hay&#39;,
 &#39;donde&#39;,
 &#39;quien&#39;,
 &#39;desde&#39;,
 &#39;todo&#39;,
 &#39;nos&#39;,
 &#39;durante&#39;,
 &#39;todos&#39;,
 &#39;uno&#39;,
 &#39;les&#39;,
 &#39;ni&#39;,
 &#39;contra&#39;,
 &#39;otros&#39;,
 &#39;ese&#39;,
 &#39;eso&#39;,
 &#39;ante&#39;,
 &#39;ellos&#39;,
 &#39;e&#39;,
 &#39;esto&#39;,
 &#39;mí&#39;,
 &#39;antes&#39;,
 &#39;algunos&#39;,
 &#39;qué&#39;,
 &#39;unos&#39;,
 &#39;yo&#39;,
 &#39;otro&#39;,
 &#39;otras&#39;,
 &#39;otra&#39;,
 &#39;él&#39;,
 &#39;tanto&#39;,
 &#39;esa&#39;,
 &#39;estos&#39;,
 &#39;mucho&#39;,
 &#39;quienes&#39;,
 &#39;nada&#39;,
 &#39;muchos&#39;,
 &#39;cual&#39;,
 &#39;poco&#39;,
 &#39;ella&#39;,
 &#39;estar&#39;,
 &#39;estas&#39;,
 &#39;algunas&#39;,
 &#39;algo&#39;,
 &#39;nosotros&#39;,
 &#39;mi&#39;,
 &#39;mis&#39;,
 &#39;tú&#39;,
 &#39;te&#39;,
 &#39;ti&#39;,
 &#39;tu&#39;,
 &#39;tus&#39;,
 &#39;ellas&#39;,
 &#39;nosotras&#39;,
 &#39;vosotros&#39;,
 &#39;vosotras&#39;,
 &#39;os&#39;,
 &#39;mío&#39;,
 &#39;mía&#39;,
 &#39;míos&#39;,
 &#39;mías&#39;,
 &#39;tuyo&#39;,
 &#39;tuya&#39;,
 &#39;tuyos&#39;,
 &#39;tuyas&#39;,
 &#39;suyo&#39;,
 &#39;suya&#39;,
 &#39;suyos&#39;,
 &#39;suyas&#39;,
 &#39;nuestro&#39;,
 &#39;nuestra&#39;,
 &#39;nuestros&#39;,
 &#39;nuestras&#39;,
 &#39;vuestro&#39;,
 &#39;vuestra&#39;,
 &#39;vuestros&#39;,
 &#39;vuestras&#39;,
 &#39;esos&#39;,
 &#39;esas&#39;,
 &#39;estoy&#39;,
 &#39;estás&#39;,
 &#39;está&#39;,
 &#39;estamos&#39;,
 &#39;estáis&#39;,
 &#39;están&#39;,
 &#39;esté&#39;,
 &#39;estés&#39;,
 &#39;estemos&#39;,
 &#39;estéis&#39;,
 &#39;estén&#39;,
 &#39;estaré&#39;,
 &#39;estarás&#39;,
 &#39;estará&#39;,
 &#39;estaremos&#39;,
 &#39;estaréis&#39;,
 &#39;estarán&#39;,
 &#39;estaría&#39;,
 &#39;estarías&#39;,
 &#39;estaríamos&#39;,
 &#39;estaríais&#39;,
 &#39;estarían&#39;,
 &#39;estaba&#39;,
 &#39;estabas&#39;,
 &#39;estábamos&#39;,
 &#39;estabais&#39;,
 &#39;estaban&#39;,
 &#39;estuve&#39;,
 &#39;estuviste&#39;,
 &#39;estuvo&#39;,
 &#39;estuvimos&#39;,
 &#39;estuvisteis&#39;,
 &#39;estuvieron&#39;,
 &#39;estuviera&#39;,
 &#39;estuvieras&#39;,
 &#39;estuviéramos&#39;,
 &#39;estuvierais&#39;,
 &#39;estuvieran&#39;,
 &#39;estuviese&#39;,
 &#39;estuvieses&#39;,
 &#39;estuviésemos&#39;,
 &#39;estuvieseis&#39;,
 &#39;estuviesen&#39;,
 &#39;estando&#39;,
 &#39;estado&#39;,
 &#39;estada&#39;,
 &#39;estados&#39;,
 &#39;estadas&#39;,
 &#39;estad&#39;,
 &#39;he&#39;,
 &#39;has&#39;,
 &#39;ha&#39;,
 &#39;hemos&#39;,
 &#39;habéis&#39;,
 &#39;han&#39;,
 &#39;haya&#39;,
 &#39;hayas&#39;,
 &#39;hayamos&#39;,
 &#39;hayáis&#39;,
 &#39;hayan&#39;,
 &#39;habré&#39;,
 &#39;habrás&#39;,
 &#39;habrá&#39;,
 &#39;habremos&#39;,
 &#39;habréis&#39;,
 &#39;habrán&#39;,
 &#39;habría&#39;,
 &#39;habrías&#39;,
 &#39;habríamos&#39;,
 &#39;habríais&#39;,
 &#39;habrían&#39;,
 &#39;había&#39;,
 &#39;habías&#39;,
 &#39;habíamos&#39;,
 &#39;habíais&#39;,
 &#39;habían&#39;,
 &#39;hube&#39;,
 &#39;hubiste&#39;,
 &#39;hubo&#39;,
 &#39;hubimos&#39;,
 &#39;hubisteis&#39;,
 &#39;hubieron&#39;,
 &#39;hubiera&#39;,
 &#39;hubieras&#39;,
 &#39;hubiéramos&#39;,
 &#39;hubierais&#39;,
 &#39;hubieran&#39;,
 &#39;hubiese&#39;,
 &#39;hubieses&#39;,
 &#39;hubiésemos&#39;,
 &#39;hubieseis&#39;,
 &#39;hubiesen&#39;,
 &#39;habiendo&#39;,
 &#39;habido&#39;,
 &#39;habida&#39;,
 &#39;habidos&#39;,
 &#39;habidas&#39;,
 &#39;soy&#39;,
 &#39;eres&#39;,
 &#39;es&#39;,
 &#39;somos&#39;,
 &#39;sois&#39;,
 &#39;son&#39;,
 &#39;sea&#39;,
 &#39;seas&#39;,
 &#39;seamos&#39;,
 &#39;seáis&#39;,
 &#39;sean&#39;,
 &#39;seré&#39;,
 &#39;serás&#39;,
 &#39;será&#39;,
 &#39;seremos&#39;,
 &#39;seréis&#39;,
 &#39;serán&#39;,
 &#39;sería&#39;,
 &#39;serías&#39;,
 &#39;seríamos&#39;,
 &#39;seríais&#39;,
 &#39;serían&#39;,
 &#39;era&#39;,
 &#39;eras&#39;,
 &#39;éramos&#39;,
 &#39;erais&#39;,
 &#39;eran&#39;,
 &#39;fui&#39;,
 &#39;fuiste&#39;,
 &#39;fue&#39;,
 &#39;fuimos&#39;,
 &#39;fuisteis&#39;,
 &#39;fueron&#39;,
 &#39;fuera&#39;,
 &#39;fueras&#39;,
 &#39;fuéramos&#39;,
 &#39;fuerais&#39;,
 &#39;fueran&#39;,
 &#39;fuese&#39;,
 &#39;fueses&#39;,
 &#39;fuésemos&#39;,
 &#39;fueseis&#39;,
 &#39;fuesen&#39;,
 &#39;sintiendo&#39;,
 &#39;sentido&#39;,
 &#39;sentida&#39;,
 &#39;sentidos&#39;,
 &#39;sentidas&#39;,
 &#39;siente&#39;,
 &#39;sentid&#39;,
 &#39;tengo&#39;,
 &#39;tienes&#39;,
 &#39;tiene&#39;,
 &#39;tenemos&#39;,
 &#39;tenéis&#39;,
 &#39;tienen&#39;,
 &#39;tenga&#39;,
 &#39;tengas&#39;,
 &#39;tengamos&#39;,
 &#39;tengáis&#39;,
 &#39;tengan&#39;,
 &#39;tendré&#39;,
 &#39;tendrás&#39;,
 &#39;tendrá&#39;,
 &#39;tendremos&#39;,
 &#39;tendréis&#39;,
 &#39;tendrán&#39;,
 &#39;tendría&#39;,
 &#39;tendrías&#39;,
 &#39;tendríamos&#39;,
 &#39;tendríais&#39;,
 &#39;tendrían&#39;,
 &#39;tenía&#39;,
 &#39;tenías&#39;,
 &#39;teníamos&#39;,
 &#39;teníais&#39;,
 &#39;tenían&#39;,
 &#39;tuve&#39;,
 &#39;tuviste&#39;,
 &#39;tuvo&#39;,
 &#39;tuvimos&#39;,
 &#39;tuvisteis&#39;,
 &#39;tuvieron&#39;,
 &#39;tuviera&#39;,
 &#39;tuvieras&#39;,
 &#39;tuviéramos&#39;,
 &#39;tuvierais&#39;,
 &#39;tuvieran&#39;,
 &#39;tuviese&#39;,
 &#39;tuvieses&#39;,
 &#39;tuviésemos&#39;,
 &#39;tuvieseis&#39;,
 &#39;tuviesen&#39;,
 &#39;teniendo&#39;,
 &#39;tenido&#39;,
 &#39;tenida&#39;,
 &#39;tenidos&#39;,
 &#39;tenidas&#39;,
 &#39;tened&#39;]
</pre></div>
</div>
</div>
</div>
<p>Otra lista de palabras de parada que podrías tomar en cuenta son los signos de puntuación.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">string</span>
<span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;!&#39;,
 &#39;&quot;&#39;,
 &#39;#&#39;,
 &#39;$&#39;,
 &#39;%&#39;,
 &#39;&amp;&#39;,
 &quot;&#39;&quot;,
 &#39;(&#39;,
 &#39;)&#39;,
 &#39;*&#39;,
 &#39;+&#39;,
 &#39;,&#39;,
 &#39;-&#39;,
 &#39;.&#39;,
 &#39;/&#39;,
 &#39;:&#39;,
 &#39;;&#39;,
 &#39;&lt;&#39;,
 &#39;=&#39;,
 &#39;&gt;&#39;,
 &#39;?&#39;,
 &#39;@&#39;,
 &#39;[&#39;,
 &#39;\\&#39;,
 &#39;]&#39;,
 &#39;^&#39;,
 &#39;_&#39;,
 &#39;`&#39;,
 &#39;{&#39;,
 &#39;|&#39;,
 &#39;}&#39;,
 &#39;~&#39;]
</pre></div>
</div>
</div>
</div>
<p>Puedes unir ambas listas para tener todo mejor organizado</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">palabras_de_parada</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;spanish&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">))</span>
<span class="n">palabras_de_parada</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;!&#39;,
 &#39;&quot;&#39;,
 &#39;#&#39;,
 &#39;$&#39;,
 &#39;%&#39;,
 &#39;&amp;&#39;,
 &quot;&#39;&quot;,
 &#39;(&#39;,
 &#39;)&#39;,
 &#39;*&#39;,
 &#39;+&#39;,
 &#39;,&#39;,
 &#39;-&#39;,
 &#39;.&#39;,
 &#39;/&#39;,
 &#39;:&#39;,
 &#39;;&#39;,
 &#39;&lt;&#39;,
 &#39;=&#39;,
 &#39;&gt;&#39;,
 &#39;?&#39;,
 &#39;@&#39;,
 &#39;[&#39;,
 &#39;\\&#39;,
 &#39;]&#39;,
 &#39;^&#39;,
 &#39;_&#39;,
 &#39;`&#39;,
 &#39;a&#39;,
 &#39;al&#39;,
 &#39;algo&#39;,
 &#39;algunas&#39;,
 &#39;algunos&#39;,
 &#39;ante&#39;,
 &#39;antes&#39;,
 &#39;como&#39;,
 &#39;con&#39;,
 &#39;contra&#39;,
 &#39;cual&#39;,
 &#39;cuando&#39;,
 &#39;de&#39;,
 &#39;del&#39;,
 &#39;desde&#39;,
 &#39;donde&#39;,
 &#39;durante&#39;,
 &#39;e&#39;,
 &#39;el&#39;,
 &#39;ella&#39;,
 &#39;ellas&#39;,
 &#39;ellos&#39;,
 &#39;en&#39;,
 &#39;entre&#39;,
 &#39;era&#39;,
 &#39;erais&#39;,
 &#39;eran&#39;,
 &#39;eras&#39;,
 &#39;eres&#39;,
 &#39;es&#39;,
 &#39;esa&#39;,
 &#39;esas&#39;,
 &#39;ese&#39;,
 &#39;eso&#39;,
 &#39;esos&#39;,
 &#39;esta&#39;,
 &#39;estaba&#39;,
 &#39;estabais&#39;,
 &#39;estaban&#39;,
 &#39;estabas&#39;,
 &#39;estad&#39;,
 &#39;estada&#39;,
 &#39;estadas&#39;,
 &#39;estado&#39;,
 &#39;estados&#39;,
 &#39;estamos&#39;,
 &#39;estando&#39;,
 &#39;estar&#39;,
 &#39;estaremos&#39;,
 &#39;estará&#39;,
 &#39;estarán&#39;,
 &#39;estarás&#39;,
 &#39;estaré&#39;,
 &#39;estaréis&#39;,
 &#39;estaría&#39;,
 &#39;estaríais&#39;,
 &#39;estaríamos&#39;,
 &#39;estarían&#39;,
 &#39;estarías&#39;,
 &#39;estas&#39;,
 &#39;este&#39;,
 &#39;estemos&#39;,
 &#39;esto&#39;,
 &#39;estos&#39;,
 &#39;estoy&#39;,
 &#39;estuve&#39;,
 &#39;estuviera&#39;,
 &#39;estuvierais&#39;,
 &#39;estuvieran&#39;,
 &#39;estuvieras&#39;,
 &#39;estuvieron&#39;,
 &#39;estuviese&#39;,
 &#39;estuvieseis&#39;,
 &#39;estuviesen&#39;,
 &#39;estuvieses&#39;,
 &#39;estuvimos&#39;,
 &#39;estuviste&#39;,
 &#39;estuvisteis&#39;,
 &#39;estuviéramos&#39;,
 &#39;estuviésemos&#39;,
 &#39;estuvo&#39;,
 &#39;está&#39;,
 &#39;estábamos&#39;,
 &#39;estáis&#39;,
 &#39;están&#39;,
 &#39;estás&#39;,
 &#39;esté&#39;,
 &#39;estéis&#39;,
 &#39;estén&#39;,
 &#39;estés&#39;,
 &#39;fue&#39;,
 &#39;fuera&#39;,
 &#39;fuerais&#39;,
 &#39;fueran&#39;,
 &#39;fueras&#39;,
 &#39;fueron&#39;,
 &#39;fuese&#39;,
 &#39;fueseis&#39;,
 &#39;fuesen&#39;,
 &#39;fueses&#39;,
 &#39;fui&#39;,
 &#39;fuimos&#39;,
 &#39;fuiste&#39;,
 &#39;fuisteis&#39;,
 &#39;fuéramos&#39;,
 &#39;fuésemos&#39;,
 &#39;ha&#39;,
 &#39;habida&#39;,
 &#39;habidas&#39;,
 &#39;habido&#39;,
 &#39;habidos&#39;,
 &#39;habiendo&#39;,
 &#39;habremos&#39;,
 &#39;habrá&#39;,
 &#39;habrán&#39;,
 &#39;habrás&#39;,
 &#39;habré&#39;,
 &#39;habréis&#39;,
 &#39;habría&#39;,
 &#39;habríais&#39;,
 &#39;habríamos&#39;,
 &#39;habrían&#39;,
 &#39;habrías&#39;,
 &#39;habéis&#39;,
 &#39;había&#39;,
 &#39;habíais&#39;,
 &#39;habíamos&#39;,
 &#39;habían&#39;,
 &#39;habías&#39;,
 &#39;han&#39;,
 &#39;has&#39;,
 &#39;hasta&#39;,
 &#39;hay&#39;,
 &#39;haya&#39;,
 &#39;hayamos&#39;,
 &#39;hayan&#39;,
 &#39;hayas&#39;,
 &#39;hayáis&#39;,
 &#39;he&#39;,
 &#39;hemos&#39;,
 &#39;hube&#39;,
 &#39;hubiera&#39;,
 &#39;hubierais&#39;,
 &#39;hubieran&#39;,
 &#39;hubieras&#39;,
 &#39;hubieron&#39;,
 &#39;hubiese&#39;,
 &#39;hubieseis&#39;,
 &#39;hubiesen&#39;,
 &#39;hubieses&#39;,
 &#39;hubimos&#39;,
 &#39;hubiste&#39;,
 &#39;hubisteis&#39;,
 &#39;hubiéramos&#39;,
 &#39;hubiésemos&#39;,
 &#39;hubo&#39;,
 &#39;la&#39;,
 &#39;las&#39;,
 &#39;le&#39;,
 &#39;les&#39;,
 &#39;lo&#39;,
 &#39;los&#39;,
 &#39;me&#39;,
 &#39;mi&#39;,
 &#39;mis&#39;,
 &#39;mucho&#39;,
 &#39;muchos&#39;,
 &#39;muy&#39;,
 &#39;más&#39;,
 &#39;mí&#39;,
 &#39;mía&#39;,
 &#39;mías&#39;,
 &#39;mío&#39;,
 &#39;míos&#39;,
 &#39;nada&#39;,
 &#39;ni&#39;,
 &#39;no&#39;,
 &#39;nos&#39;,
 &#39;nosotras&#39;,
 &#39;nosotros&#39;,
 &#39;nuestra&#39;,
 &#39;nuestras&#39;,
 &#39;nuestro&#39;,
 &#39;nuestros&#39;,
 &#39;o&#39;,
 &#39;os&#39;,
 &#39;otra&#39;,
 &#39;otras&#39;,
 &#39;otro&#39;,
 &#39;otros&#39;,
 &#39;para&#39;,
 &#39;pero&#39;,
 &#39;poco&#39;,
 &#39;por&#39;,
 &#39;porque&#39;,
 &#39;que&#39;,
 &#39;quien&#39;,
 &#39;quienes&#39;,
 &#39;qué&#39;,
 &#39;se&#39;,
 &#39;sea&#39;,
 &#39;seamos&#39;,
 &#39;sean&#39;,
 &#39;seas&#39;,
 &#39;sentid&#39;,
 &#39;sentida&#39;,
 &#39;sentidas&#39;,
 &#39;sentido&#39;,
 &#39;sentidos&#39;,
 &#39;seremos&#39;,
 &#39;será&#39;,
 &#39;serán&#39;,
 &#39;serás&#39;,
 &#39;seré&#39;,
 &#39;seréis&#39;,
 &#39;sería&#39;,
 &#39;seríais&#39;,
 &#39;seríamos&#39;,
 &#39;serían&#39;,
 &#39;serías&#39;,
 &#39;seáis&#39;,
 &#39;siente&#39;,
 &#39;sin&#39;,
 &#39;sintiendo&#39;,
 &#39;sobre&#39;,
 &#39;sois&#39;,
 &#39;somos&#39;,
 &#39;son&#39;,
 &#39;soy&#39;,
 &#39;su&#39;,
 &#39;sus&#39;,
 &#39;suya&#39;,
 &#39;suyas&#39;,
 &#39;suyo&#39;,
 &#39;suyos&#39;,
 &#39;sí&#39;,
 &#39;también&#39;,
 &#39;tanto&#39;,
 &#39;te&#39;,
 &#39;tendremos&#39;,
 &#39;tendrá&#39;,
 &#39;tendrán&#39;,
 &#39;tendrás&#39;,
 &#39;tendré&#39;,
 &#39;tendréis&#39;,
 &#39;tendría&#39;,
 &#39;tendríais&#39;,
 &#39;tendríamos&#39;,
 &#39;tendrían&#39;,
 &#39;tendrías&#39;,
 &#39;tened&#39;,
 &#39;tenemos&#39;,
 &#39;tenga&#39;,
 &#39;tengamos&#39;,
 &#39;tengan&#39;,
 &#39;tengas&#39;,
 &#39;tengo&#39;,
 &#39;tengáis&#39;,
 &#39;tenida&#39;,
 &#39;tenidas&#39;,
 &#39;tenido&#39;,
 &#39;tenidos&#39;,
 &#39;teniendo&#39;,
 &#39;tenéis&#39;,
 &#39;tenía&#39;,
 &#39;teníais&#39;,
 &#39;teníamos&#39;,
 &#39;tenían&#39;,
 &#39;tenías&#39;,
 &#39;ti&#39;,
 &#39;tiene&#39;,
 &#39;tienen&#39;,
 &#39;tienes&#39;,
 &#39;todo&#39;,
 &#39;todos&#39;,
 &#39;tu&#39;,
 &#39;tus&#39;,
 &#39;tuve&#39;,
 &#39;tuviera&#39;,
 &#39;tuvierais&#39;,
 &#39;tuvieran&#39;,
 &#39;tuvieras&#39;,
 &#39;tuvieron&#39;,
 &#39;tuviese&#39;,
 &#39;tuvieseis&#39;,
 &#39;tuviesen&#39;,
 &#39;tuvieses&#39;,
 &#39;tuvimos&#39;,
 &#39;tuviste&#39;,
 &#39;tuvisteis&#39;,
 &#39;tuviéramos&#39;,
 &#39;tuviésemos&#39;,
 &#39;tuvo&#39;,
 &#39;tuya&#39;,
 &#39;tuyas&#39;,
 &#39;tuyo&#39;,
 &#39;tuyos&#39;,
 &#39;tú&#39;,
 &#39;un&#39;,
 &#39;una&#39;,
 &#39;uno&#39;,
 &#39;unos&#39;,
 &#39;vosotras&#39;,
 &#39;vosotros&#39;,
 &#39;vuestra&#39;,
 &#39;vuestras&#39;,
 &#39;vuestro&#39;,
 &#39;vuestros&#39;,
 &#39;y&#39;,
 &#39;ya&#39;,
 &#39;yo&#39;,
 &#39;{&#39;,
 &#39;|&#39;,
 &#39;}&#39;,
 &#39;~&#39;,
 &#39;él&#39;,
 &#39;éramos&#39;}
</pre></div>
</div>
</div>
</div>
<p>Finalmente solo queda eliminar las palabras de parada del texto de la noticia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">palabras_noticia_sin_palabras_de_parada</span> <span class="o">=</span> <span class="p">[</span><span class="n">palabra</span> <span class="k">for</span> <span class="n">palabra</span> <span class="ow">in</span> <span class="n">palabras_noticia</span> <span class="k">if</span> <span class="n">palabra</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">palabras_de_parada</span><span class="p">]</span>
<span class="n">palabras_noticia_sin_palabras_de_parada</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Los&#39;,
 &#39;clubes&#39;,
 &#39;cochabambinos&#39;,
 &#39;Olympic&#39;,
 &#39;Albert&#39;,
 &#39;Einstein&#39;,
 &#39;paceño&#39;,
 &#39;Universidad&#39;,
 &#39;Católica&#39;,
 &#39;Boliviana&#39;,
 &#39;UCB&#39;,
 &#39;avanzan&#39;,
 &#39;paso&#39;,
 &#39;firme&#39;,
 &#39;constante&#39;,
 &#39;rumbo&#39;,
 &#39;corona&#39;,
 &#39;Liga&#39;,
 &#39;Superior&#39;,
 &#39;voleibol&#39;,
 &#39;rama&#39;,
 &#39;femenina&#39;,
 &#39;desarrolla&#39;,
 &#39;coliseo&#39;,
 &#39;Julio&#39;,
 &#39;Borelli&#39;,
 &#39;Vitterito&#39;,
 &#39;La&#39;,
 &#39;Paz&#39;,
 &#39;luego&#39;,
 &#39;cosechar&#39;,
 &#39;sendas&#39;,
 &#39;victorias&#39;,
 &#39;noche&#39;,
 &#39;martes&#39;,
 &#39;El&#39;,
 &#39;ganador&#39;,
 &#39;representante&#39;,
 &#39;Bolivia&#39;,
 &#39;Liga&#39;,
 &#39;Sudamericana&#39;,
 &#39;Clubes&#39;,
 &#39;2020&#39;,
 &#39;El&#39;,
 &#39;campeón&#39;,
 &#39;defensor&#39;,
 &#39;título&#39;,
 &#39;Olympic&#39;,
 &#39;superó&#39;,
 &#39;3-0&#39;,
 &#39;verdugo&#39;,
 &#39;final&#39;,
 &#39;edición&#39;,
 &#39;2017&#39;,
 &#39;cochabambino&#39;,
 &#39;San&#39;,
 &#39;Simón&#39;,
 &#39;La&#39;,
 &#39;victoria&#39;,
 &#39;olympiquistas&#39;,
 &#39;sets&#39;,
 &#39;25-14&#39;,
 &#39;25-13&#39;,
 &#39;25-18&#39;]
</pre></div>
</div>
</div>
</div>
<p><a id="4"></a></p>
</div>
<div class="section" id="otras-tareas-de-limpieza-que-se-pueden-considerar">
<h2>Otras tareas de limpieza que se pueden considerar<a class="headerlink" href="#otras-tareas-de-limpieza-que-se-pueden-considerar" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Unificar el case - <font color="gray">string.lower()&gt;</font>.</p></li>
<li><p>Quitar acentos (probablemente no es buena idea si el contenido está en español)</p></li>
<li><p>Procesar contracciones. I’m -&gt; I am</p></li>
<li><p>Quitar caracteres expeciales. Como los siguientes: #&#64;!</p></li>
<li><p>Quitar markup. Ejemplo en contenido HTML</p></li>
<li><p>Corregir texto. Ejemplo, noooo por favoooorrr -&gt; no por favor</p></li>
</ul>
<p>Algunos enlaces de utilidad:</p>
<ul class="simple">
<li><p>http://norvig.com/spell-correct.html</p></li>
<li><p>https://github.com/fsondej/autocorrect</p></li>
<li><p>https://github.com/MajorTal/DeepSpell</p></li>
</ul>
<p><a id="5"></a></p>
</div>
<div class="section" id="lematizacion">
<h2>Lematización<a class="headerlink" href="#lematizacion" title="Permalink to this headline">¶</a></h2>
<p>Eliminar las variaciones de la misma palabra para tratar las variaciones como una sola entidad. (<em>close, closed, closing</em>; caminaba, caminando, caminar). Al igual que la eliminación de palabras de parada, se emplea para reducir la cantidad de elementos en el vocabulario de un problema.</p>
<p>Algunos enlaces que podrían servirte de ayuda:</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://es.wikipedia.org/wiki/Lematizaci%C3%B3n">Lematización</a></strong></p></li>
<li><p><strong><a class="reference external" href="http://stemmer-es.sourceforge.net/">Stemmer-es, Un lematizador de español</a></strong></p></li>
</ul>
<p><a id="6"></a></p>
</div>
<div class="section" id="identificar-n-gramas">
<h2>Identificar n-gramas<a class="headerlink" href="#identificar-n-gramas" title="Permalink to this headline">¶</a></h2>
<p>Grupos de N palabras que están siempre juntas (Nueva York, Santa Cruz) y que deben tratarse como una sola entidad/palabra.</p>
<p>Algunos enlaces que podrían servirte de ayuda:</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://es.wikipedia.org/wiki/Modelo_bolsa_de_palabras">Modelo bolsa de palabras</a></strong></p></li>
<li><p><strong><a class="reference external" href="https://es.wikipedia.org/wiki/N-grama">N-grama</a></strong></p></li>
</ul>
<p><a id="7"></a></p>
</div>
<div class="section" id="desambiguacion-linguistica-word-sense-disambiguation">
<h2>Desambiguación lingüística (<em>Word Sense Disambiguation</em>)<a class="headerlink" href="#desambiguacion-linguistica-word-sense-disambiguation" title="Permalink to this headline">¶</a></h2>
<p>Asignar significado en base al contexto. ¿Con qué sentido se usa una palabra? En el caso de la <strong><a class="reference external" href="https://es.wikipedia.org/wiki/Polisemia">polisemia</a></strong>, ¿cuál de los significados es el más apropiado dado el contexto?</p>
<p>Ejemplos:</p>
<ul class="simple">
<li><p>Placeres de la carne.</p></li>
<li><p>La carne está sabrosa.</p></li>
<li><p>Puso dos velas a San Pedro.</p></li>
<li><p>Los egipcios fueron los primeros constructores de barcos de vela de los que se tiene noticia.</p></li>
</ul>
<p>El desarrollo de algoritmos para reproducir esta capacidad humana (desambiguar el significado) a menudo puede ser una  <strong><a class="reference external" href="https://es.wikipedia.org/wiki/Problema_no_resuelto">tarea muy difícil</a></strong>. En la frase “La carne está sabrosa” hay también cierto contenido implícito: se asume que estamos hablando de carne cocida.</p>
<p>Algunos enlaces que podrían servirte de ayuda:</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://es.wikipedia.org/wiki/Desambiguaci%C3%B3n_ling%C3%BC%C3%ADstica">Desambiguación lingüística</a></strong></p></li>
</ul>
<p>Recursos lingüísticos</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://es.wikipedia.org/wiki/WordNet">WordNet</a></strong></p></li>
<li><p><strong><a class="reference external" href="http://timm.ujaen.es/recursos/spanish-wordnet-3-0/">Spanish WordNet 3.0</a></strong></p></li>
</ul>
<p>Estrategias</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://en.wikipedia.org/wiki/Lesk_algorithm">Algoritmo Lesk</a></strong></p></li>
<li><p><strong><a class="reference external" href="http://dpinto.cs.buap.mx/pln/Autumn2010/wsd.pdf">Desambiguación del Sentido de las Palabras</a></strong></p></li>
<li><p><strong><a class="reference external" href="https://pdfs.semanticscholar.org/cd5f/5dd14c126325a81280407ddc2616f3704fca.pdf">Estudio sobre métodos tipo Lesk usados para la desambiguación de sentidos de palabras</a></strong></p></li>
<li><p><strong><a class="reference external" href="http://www.sepln.org/sites/default/files/monografia/archivos/2018-10/monografiaDavid.pdf">Supervised Word Sense Disambiguation: Facing Current Challenges</a></strong></p></li>
</ul>
<p><a id="8"></a></p>
</div>
<div class="section" id="etiquetado-gramatical-part-of-speech-tagging">
<h2>Etiquetado gramatical (<em>Part of Speech Tagging</em>)<a class="headerlink" href="#etiquetado-gramatical-part-of-speech-tagging" title="Permalink to this headline">¶</a></h2>
<p>Como parte de la desambiguación, se suele realizar la tarea de asignar una categoría a cada palabra: sujeto, nombre, verbo, adjetivo.</p>
<p>Algunos enlaces de ayuda:</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://es.wikipedia.org/wiki/Etiquetado_gramatical">Etiquetado gramatical</a></strong></p></li>
<li><p><strong><a class="reference external" href="https://www.cnts.ua.ac.be/pages/using-wikicorpus-nltk-to-build-a-spanish-part-of-speech-tagger">Using Wikicorpus &amp; NLTK to build a Spanish part-of-speech tagger</a></strong></p></li>
<li><p><strong><a class="reference external" href="https://www.researchgate.net/publication/282828110_Choosing_a_Spanish_Part-of-Speech_tagger_for_a_lexically_sensitive_task">Choosing a Spanish Part-of-Speech tagger for a lexically sensitive task</a></strong></p></li>
</ul>
<p><a id="9"></a></p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="representacion-del-texto">
<h1>Representación del texto<a class="headerlink" href="#representacion-del-texto" title="Permalink to this headline">¶</a></h1>
<p>Dependiendo del tipo de problema <em>NLP</em>, el texto deberá transformarse en una representación adecuada para las herramientas y algoritmos empleandos para abordar el problema. Una de las más usadas es crear representaciones numéricas. Esencialmente, se trata de convertir texto en un vector/arreglo de números.</p>
<p>Los valores en el arreglo pueden ser por ejemplo: la frequencia del <em>tóken</em> en el documento, el código en un <em>word embedding</em>, o la métrica <em>TF-IDF</em>.</p>
<p>Hay escenarios en los cuales estos vectores pueden tener un gran tamaño, en estos casos se recomienda emplear alguna estrategia para reducir la dimensionalidad de los vectores (Ej. <em>feature hashing</em>, <em>locality sensitive hashing</em>).</p>
<p>Para su mejor comprensión, realizaremos la representación sobre la base de esta <a class="reference external" href="https://www.lostiempos.com/deportes/multideportivo/20200115/olympic-albert-einstein-ucb-lpz-van-paso-firme-liga-superior">noticia</a></p>
<p>Primero debemos obtener el texto de la noticia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">texto_noticia</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Los clubes cochabambinos de Olympic, Albert Einstein y el paceño Universidad Católica Boliviana (UCB) avanzan a paso firme y constante rumbo a la corona en la Liga Superior de voleibol, rama femenina, que se desarrolla en el coliseo Julio Borelli Vitterito de La Paz, luego de cosechar sendas victorias la noche de este martes. El ganador será representante de Bolivia en la Liga Sudamericana de Clubes 2020.</span>

<span class="s2">El campeón defensor del título, Olympic, superó 3-0  a su verdugo de la final de la edición 2017, el también cochabambino San Simón. La victoria para las olympiquistas fue con sets de 25-14, 25-13 y 25-14.&quot;&quot;&quot;</span>
<span class="n">texto_noticia</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Los clubes cochabambinos de Olympic, Albert Einstein y el paceño Universidad Católica Boliviana (UCB) avanzan a paso firme y constante rumbo a la corona en la Liga Superior de voleibol, rama femenina, que se desarrolla en el coliseo Julio Borelli Vitterito de La Paz, luego de cosechar sendas victorias la noche de este martes. El ganador será representante de Bolivia en la Liga Sudamericana de Clubes 2020.\n\nEl campeón defensor del título, Olympic, superó 3-0  a su verdugo de la final de la edición 2017, el también cochabambino San Simón. La victoria para las olympiquistas fue con sets de 25-14, 25-13 y 25-14.&#39;
</pre></div>
</div>
</div>
</div>
<p>Ahora debemos importar las librerias correspondientes y generar la lista de <em>stop words</em> en español.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># nltk.download(&#39;stopwords&#39;) # Si no está ya descargado</span>

<span class="n">palabras_de_parada_espanol</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;spanish&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Luego proceguimos a tokenizar el texto a nivel oración.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># nltk.download(&#39;punkt&#39;) # Si no está ya presente</span>

<span class="n">oraciones_noticia</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">texto_noticia</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s1">&#39;spanish&#39;</span><span class="p">)</span>
<span class="n">oraciones_noticia</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Los clubes cochabambinos de Olympic, Albert Einstein y el paceño Universidad Católica Boliviana (UCB) avanzan a paso firme y constante rumbo a la corona en la Liga Superior de voleibol, rama femenina, que se desarrolla en el coliseo Julio Borelli Vitterito de La Paz, luego de cosechar sendas victorias la noche de este martes.&#39;
</pre></div>
</div>
</div>
</div>
<p>Creamos una funcion para eliminar las palabras de parada de una oración.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normalizar_oraciones</span><span class="p">(</span><span class="n">oraciones</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s1">&#39;spanish&#39;</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">oraciones</span><span class="p">,</span><span class="n">language</span><span class="p">)</span>
    <span class="n">tokens_filtrados</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">palabras_de_parada_espanol</span><span class="p">]</span>
    <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens_filtrados</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Aplicamos la función a todo el cuerpo del texto.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normalizar_cuerpo_texto</span><span class="p">(</span><span class="n">oraciones</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s1">&#39;spanish&#39;</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">normalizar_oraciones</span><span class="p">(</span><span class="n">oracion</span><span class="p">,</span> <span class="n">language</span><span class="p">)</span> <span class="k">for</span> <span class="n">oracion</span> <span class="ow">in</span> <span class="n">oraciones</span><span class="p">])</span>

<span class="n">cuerpo_texto_normalizado</span> <span class="o">=</span> <span class="n">normalizar_cuerpo_texto</span><span class="p">(</span><span class="n">oraciones_noticia</span><span class="p">)</span>
<span class="n">cuerpo_texto_normalizado</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;los clubes cochabambinos olympic albert einstein paceño universidad católica boliviana ucb avanzan paso firme constante rumbo corona liga superior voleibol rama femenina desarrolla coliseo julio borelli vitterito la paz luego cosechar sendas victorias noche martes&#39;,
       &#39;el ganador representante bolivia liga sudamericana clubes 2020&#39;,
       &#39;el campeón defensor título olympic superó 3-0 verdugo final edición 2017 cochabambino san simón&#39;,
       &#39;la victoria olympiquistas sets 25-14 25-13 25-14&#39;], dtype=&#39;&lt;U264&#39;)
</pre></div>
</div>
</div>
</div>
<p>Muy bien, ahora obtendremos el vocabulario del problema con el siguiente código.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">obtener_vocabulario_problema</span><span class="p">(</span><span class="n">cuerpo_texto_normalizado</span><span class="p">):</span>
    <span class="n">vocabulario_problema</span> <span class="o">=</span> <span class="p">[]</span> 
    <span class="k">for</span> <span class="n">oracion</span> <span class="ow">in</span> <span class="n">cuerpo_texto_normalizado</span><span class="p">:</span>
        <span class="n">vocabulario_problema</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">oracion</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>  
    <span class="k">return</span> <span class="n">vocabulario_problema</span>
</pre></div>
</div>
</div>
</div>
<p>Con la siguiente función, tendremos cada palabra del vocabulario con su posición.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">obtener_vocabulario_problema_y_posicion</span><span class="p">(</span><span class="n">vocabulario_del_problema_ordenado</span><span class="p">):</span>
    <span class="n">token_y_su_posicion</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocabulario_del_problema_ordenado</span><span class="p">):</span>
        <span class="n">token_y_su_posicion</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="k">return</span> <span class="n">token_y_su_posicion</span>

<span class="n">vocabulario_problema</span> <span class="o">=</span> <span class="n">obtener_vocabulario_problema</span><span class="p">(</span><span class="n">cuerpo_texto_normalizado</span><span class="p">)</span>
<span class="n">vocabulario_problema_ordenado</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">vocabulario_problema</span><span class="p">))</span>
<span class="n">vocabulario_problema_y_su_posicion</span> <span class="o">=</span> <span class="n">obtener_vocabulario_problema_y_posicion</span><span class="p">(</span><span class="n">vocabulario_problema_ordenado</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cantidad de palabras:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocabulario_problema_y_su_posicion</span><span class="p">))</span>
<span class="n">vocabulario_problema_y_su_posicion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cantidad de palabras: 58
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;2017&#39;: 0,
 &#39;2020&#39;: 1,
 &#39;25-13&#39;: 2,
 &#39;25-14&#39;: 3,
 &#39;3-0&#39;: 4,
 &#39;albert&#39;: 5,
 &#39;avanzan&#39;: 6,
 &#39;bolivia&#39;: 7,
 &#39;boliviana&#39;: 8,
 &#39;borelli&#39;: 9,
 &#39;campeón&#39;: 10,
 &#39;católica&#39;: 11,
 &#39;clubes&#39;: 12,
 &#39;cochabambino&#39;: 13,
 &#39;cochabambinos&#39;: 14,
 &#39;coliseo&#39;: 15,
 &#39;constante&#39;: 16,
 &#39;corona&#39;: 17,
 &#39;cosechar&#39;: 18,
 &#39;defensor&#39;: 19,
 &#39;desarrolla&#39;: 20,
 &#39;edición&#39;: 21,
 &#39;einstein&#39;: 22,
 &#39;el&#39;: 23,
 &#39;femenina&#39;: 24,
 &#39;final&#39;: 25,
 &#39;firme&#39;: 26,
 &#39;ganador&#39;: 27,
 &#39;julio&#39;: 28,
 &#39;la&#39;: 29,
 &#39;liga&#39;: 30,
 &#39;los&#39;: 31,
 &#39;luego&#39;: 32,
 &#39;martes&#39;: 33,
 &#39;noche&#39;: 34,
 &#39;olympic&#39;: 35,
 &#39;olympiquistas&#39;: 36,
 &#39;paceño&#39;: 37,
 &#39;paso&#39;: 38,
 &#39;paz&#39;: 39,
 &#39;rama&#39;: 40,
 &#39;representante&#39;: 41,
 &#39;rumbo&#39;: 42,
 &#39;san&#39;: 43,
 &#39;sendas&#39;: 44,
 &#39;sets&#39;: 45,
 &#39;simón&#39;: 46,
 &#39;sudamericana&#39;: 47,
 &#39;superior&#39;: 48,
 &#39;superó&#39;: 49,
 &#39;título&#39;: 50,
 &#39;ucb&#39;: 51,
 &#39;universidad&#39;: 52,
 &#39;verdugo&#39;: 53,
 &#39;victoria&#39;: 54,
 &#39;victorias&#39;: 55,
 &#39;vitterito&#39;: 56,
 &#39;voleibol&#39;: 57}
</pre></div>
</div>
</div>
</div>
<p><a id="10"></a></p>
<div class="section" id="one-hot-encoding-tuplas-de-palabras">
<h2>One-hot encoding (tuplas de palabras)<a class="headerlink" href="#one-hot-encoding-tuplas-de-palabras" title="Permalink to this headline">¶</a></h2>
<p>Los <em>feature vectors</em> se utilizan para representar características simbólicas o númericas; llamados <em>features</em>, de un objeto de una manera matemática y fácilmente analizable.</p>
<p>Se crea un vocabulario con todas la palabras de todos los documentos. Y cada documento se representa como una arreglo donde se indica la presencia o ausencia de una palabra en el documento.</p>
<p><img alt="one-hot-encoding" src="../../_images/03-one-hot-encoding.png" /></p>
<ul class="simple">
<li><p>Cada documento se representa con uno arreglo tan grande como todo el vocabulario! :(</p></li>
<li><p>Se pierde el órden y la frequencia de las palabras.</p></li>
<li><p>No captura relaciones entre palabras.</p></li>
<li><p>Su mayor ventaja es la simplicidad.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cuerpo_texto_normalizado</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;el campeón defensor título olympic superó 3-0 verdugo final edición 2017 cochabambino san simón&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">vector_one_hot</span><span class="p">(</span><span class="n">oracion</span><span class="p">,</span> <span class="n">vocabulario_problema_y_su_posicion</span><span class="p">):</span>
    <span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabulario_problema_y_su_posicion</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">oracion</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="n">vector</span><span class="p">[</span><span class="n">vocabulario_problema_y_su_posicion</span><span class="p">[</span><span class="n">token</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">vector</span>

<span class="n">vector_one_hot</span><span class="p">(</span><span class="n">cuerpo_texto_normalizado</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">vocabulario_problema_y_su_posicion</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,
       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0])
</pre></div>
</div>
</div>
</div>
<p><a id="11"></a></p>
</div>
<div class="section" id="tf-idf-term-frequency-inverse-document-frequency">
<h2>TF-IDF (Term frequency, inverse document frequency)<a class="headerlink" href="#tf-idf-term-frequency-inverse-document-frequency" title="Permalink to this headline">¶</a></h2>
<p><strong>Conteos</strong></p>
<p>El vector de cada documento contiene la cantidad de veces que aparece una palabra (no solo se marca su presencia/ausencia)</p>
<p><strong>TF-IDF (Term frequency, inverse document frequency)</strong></p>
<p><em>TF</em>: La frecuencia de una palabra en un documento.</p>
<p><em>IDF</em>: Mientras en más documentos aparece menos significativa es la palabra en los documentos en las aparece.</p>
<p>Captura la frequencia de las palabras en cada documento y en el contenido formado por el conjunto de los documentos.</p>
<p>El valor de <em>TF-IDF</em> para cada palabra aumenta por su frecuencia en un documento pero disminuye si al mismo tiempo aparece
todo el conjunto de documentos (es un término común).</p>
<p>La idea es capturar la importancia de las palabras en los documentos. No captura las relaciones entre las palabras.</p>
<div class="section" id="tf-term-frequency">
<h3>TF  (Term Frequency)<a class="headerlink" href="#tf-term-frequency" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cuerpo_texto_normalizado</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;los clubes cochabambinos olympic albert einstein paceño universidad católica boliviana ucb avanzan paso firme constante rumbo corona liga superior voleibol rama femenina desarrolla coliseo julio borelli vitterito la paz luego cosechar sendas victorias noche martes&#39;,
       &#39;el ganador representante bolivia liga sudamericana clubes 2020&#39;,
       &#39;el campeón defensor título olympic superó 3-0 verdugo final edición 2017 cochabambino san simón&#39;,
       &#39;la victoria olympiquistas sets 25-14 25-13 25-14&#39;], dtype=&#39;&lt;U264&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocabulario_problema_y_su_posicion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;2017&#39;: 0,
 &#39;2020&#39;: 1,
 &#39;25-13&#39;: 2,
 &#39;25-14&#39;: 3,
 &#39;3-0&#39;: 4,
 &#39;albert&#39;: 5,
 &#39;avanzan&#39;: 6,
 &#39;bolivia&#39;: 7,
 &#39;boliviana&#39;: 8,
 &#39;borelli&#39;: 9,
 &#39;campeón&#39;: 10,
 &#39;católica&#39;: 11,
 &#39;clubes&#39;: 12,
 &#39;cochabambino&#39;: 13,
 &#39;cochabambinos&#39;: 14,
 &#39;coliseo&#39;: 15,
 &#39;constante&#39;: 16,
 &#39;corona&#39;: 17,
 &#39;cosechar&#39;: 18,
 &#39;defensor&#39;: 19,
 &#39;desarrolla&#39;: 20,
 &#39;edición&#39;: 21,
 &#39;einstein&#39;: 22,
 &#39;el&#39;: 23,
 &#39;femenina&#39;: 24,
 &#39;final&#39;: 25,
 &#39;firme&#39;: 26,
 &#39;ganador&#39;: 27,
 &#39;julio&#39;: 28,
 &#39;la&#39;: 29,
 &#39;liga&#39;: 30,
 &#39;los&#39;: 31,
 &#39;luego&#39;: 32,
 &#39;martes&#39;: 33,
 &#39;noche&#39;: 34,
 &#39;olympic&#39;: 35,
 &#39;olympiquistas&#39;: 36,
 &#39;paceño&#39;: 37,
 &#39;paso&#39;: 38,
 &#39;paz&#39;: 39,
 &#39;rama&#39;: 40,
 &#39;representante&#39;: 41,
 &#39;rumbo&#39;: 42,
 &#39;san&#39;: 43,
 &#39;sendas&#39;: 44,
 &#39;sets&#39;: 45,
 &#39;simón&#39;: 46,
 &#39;sudamericana&#39;: 47,
 &#39;superior&#39;: 48,
 &#39;superó&#39;: 49,
 &#39;título&#39;: 50,
 &#39;ucb&#39;: 51,
 &#39;universidad&#39;: 52,
 &#39;verdugo&#39;: 53,
 &#39;victoria&#39;: 54,
 &#39;victorias&#39;: 55,
 &#39;vitterito&#39;: 56,
 &#39;voleibol&#39;: 57}
</pre></div>
</div>
</div>
</div>
<p>Contamos la frecuencia de cada <em>token</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokens_y_su_frecuencia</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">cuerpo_texto_normalizado</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">tokens_y_su_frecuencia</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Counter({&#39;la&#39;: 1,
         &#39;victoria&#39;: 1,
         &#39;olympiquistas&#39;: 1,
         &#39;sets&#39;: 1,
         &#39;25-14&#39;: 2,
         &#39;25-13&#39;: 1})
</pre></div>
</div>
</div>
</div>
<p>Puedes contar también de esta forma:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">frecuencia</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="s1">&#39;c&#39;</span><span class="p">,</span><span class="s1">&#39;a&#39;</span><span class="p">])</span>
<span class="n">frecuencia</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Counter({&#39;a&#39;: 2, &#39;b&#39;: 1, &#39;c&#39;: 1})
</pre></div>
</div>
</div>
</div>
<p>Con el siguiente código puedes obtener todos los <em>tokens</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">heapq</span> <span class="kn">import</span> <span class="n">nlargest</span>

<span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">frecuencia</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">frecuencia</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
</pre></div>
</div>
</div>
</div>
<p>La siguiente función anota la frecuencia de cada palabra en el vector <em>one hot</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">obtener_vector_frecuencia_termino</span><span class="p">(</span><span class="n">oracion</span><span class="p">,</span> <span class="n">vocabulario_problema_y_su_posicion</span><span class="p">):</span>
    <span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabulario_problema_y_su_posicion</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">tokens_y_su_frecuencia</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">oracion</span><span class="o">.</span><span class="n">split</span><span class="p">());</span>
    <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">frecuencia</span> <span class="ow">in</span> <span class="n">tokens_y_su_frecuencia</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">vector</span><span class="p">[</span><span class="n">vocabulario_problema_y_su_posicion</span><span class="p">[</span><span class="n">token</span><span class="p">]]</span> <span class="o">=</span> <span class="n">frecuencia</span>
    <span class="k">return</span> <span class="n">vector</span>

<span class="n">obtener_vector_frecuencia_termino</span><span class="p">(</span><span class="n">cuerpo_texto_normalizado</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">vocabulario_problema_y_su_posicion</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])
</pre></div>
</div>
</div>
</div>
<p><em><strong>Evite escribir código, cuando se puede hacer con librerias</strong></em></p>
<p>Un enlace de ayuda:
<strong><a class="reference external" href="https://towardsdatascience.com/scikit-learn-design-principles-d1371958059b">Scikit-Learn Design Principles</a></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simple_cuerpo_texto_normalizado</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;p1 co&#39;</span><span class="p">,</span><span class="s1">&#39;p2 co co&#39;</span><span class="p">])</span>
<span class="n">simple_cuerpo_texto_normalizado</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;p1 co&#39;, &#39;p2 co co&#39;], dtype=&#39;&lt;U8&#39;)
</pre></div>
</div>
</div>
</div>
<p>La funcion <font color="gray">CountVectorizer()</font> implementa <font color="gray">transform</font></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">cv_matris</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">simple_cuerpo_texto_normalizado</span><span class="p">)</span>
<span class="n">cv_matris</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;2x3 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
	with 4 stored elements in Compressed Sparse Row format&gt;
</pre></div>
</div>
</div>
</div>
<p>Algunos ejemplos más:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matriz disperza:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv_matris</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vecto np regular:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv_matris</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vocabulario:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variables:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;one-hot encoding:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">cv_matris</span><span class="o">.</span><span class="n">toarray</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matriz disperza:
  (0, 1)	1
  (0, 0)	1
  (1, 0)	2
  (1, 2)	1
Vecto np regular:
[[1 1 0]
 [2 0 1]]
Vocabulario:
{&#39;p1&#39;: 1, &#39;co&#39;: 0, &#39;p2&#39;: 2}
Variables:
[&#39;co&#39;, &#39;p1&#39;, &#39;p2&#39;]
one-hot encoding:
[[1 1 0]
 [1 0 1]]
</pre></div>
</div>
</div>
</div>
<p>Puedes también utilizar los <em>dataframes</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_matris</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>co</th>
      <th>p1</th>
      <th>p2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Ahora unos ejemplos para bi-gramas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simple_cuerpo_texto_normalizado</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;p1 co&#39;, &#39;p2 co co&#39;], dtype=&#39;&lt;U8&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">cv_matris_con_bigramas</span> <span class="o">=</span> <span class="n">bv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">simple_cuerpo_texto_normalizado</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matris dispersa:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv_matris_con_bigramas</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vector np regular:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv_matris_con_bigramas</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variables:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matris dispersa:
  (0, 2)	1
  (0, 0)	1
  (0, 3)	1
  (1, 0)	2
  (1, 4)	1
  (1, 5)	1
  (1, 1)	1
Vector np regular:
[[1 0 1 1 0 0]
 [2 1 0 0 1 1]]
Variables:
[&#39;co&#39;, &#39;co co&#39;, &#39;p1&#39;, &#39;p1 co&#39;, &#39;p2&#39;, &#39;p2 co&#39;]
</pre></div>
</div>
</div>
</div>
<p>Puedes también utilizar <em>dataframes</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_matris_con_bigramas</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">bv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>co</th>
      <th>co co</th>
      <th>p1</th>
      <th>p1 co</th>
      <th>p2</th>
      <th>p2 co</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="idf-inverse-document-frequency">
<h3>IDF  (Inverse Document Frequency)<a class="headerlink" href="#idf-inverse-document-frequency" title="Permalink to this headline">¶</a></h3>
<p>idf(t) = log(cantidad-documentos/cantidad-documentos-con-el-termino)</p>
<p>Min = 1; A valores más alejados de 1, mayor IDF</p>
<p>Interpretación de resultados</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simple_cuerpo_texto_normalizado</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;p1 co&#39;</span><span class="p">,</span><span class="s1">&#39;p2 co co&#39;</span><span class="p">])</span>
<span class="n">simple_cuerpo_texto_normalizado</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;p1 co&#39;, &#39;p2 co co&#39;], dtype=&#39;&lt;U8&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="n">tfIdfv</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">)</span>
<span class="n">tfIdfv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">simple_cuerpo_texto_normalizado</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TfidfVectorizer()
</pre></div>
</div>
</div>
</div>
<p>Fijate lo que pasa con el valor idf para las palabras que aparecen en muchos documentos. Debido a cómo sckit-learn hace los cálculos, no hay IDF = 0, el valor mínimo es 1</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">tfIdfv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">(),</span><span class="n">tfIdfv</span><span class="o">.</span><span class="n">idf_</span> <span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;co&#39;: 1.0, &#39;p1&#39;: 1.4054651081081644, &#39;p2&#39;: 1.4054651081081644}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simple_cuerpo_texto_normalizado</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;p1 co co&#39;</span><span class="p">,</span><span class="s1">&#39;p2 co&#39;</span><span class="p">])</span>
<span class="n">tfIdfv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">simple_cuerpo_texto_normalizado</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TfidfVectorizer()
</pre></div>
</div>
</div>
</div>
<p>Este <em>score</em>/indicador aumenta con la frequencia de la palabra en el documento, pero disminuye cuando la palabra se hace muy común (baja su relevancia)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tt_matris</span> <span class="o">=</span> <span class="n">tfIdfv</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">simple_cuerpo_texto_normalizado</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vector np regular:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tt_matris</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variables:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tfIdfv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Vector np regular:
[[0.81818021 0.57496187 0.        ]
 [0.57973867 0.         0.81480247]]
Variables:
[&#39;co&#39;, &#39;p1&#39;, &#39;p2&#39;]
</pre></div>
</div>
</div>
</div>
<p><a id="12"></a></p>
</div>
</div>
<div class="section" id="word-embeddings">
<h2>Word embeddings<a class="headerlink" href="#word-embeddings" title="Permalink to this headline">¶</a></h2>
<p>Asociación de palabras con códigos numéricos que capturan su similitud semánticas. Por ejemplo, Londres tendrá un valor numérico cercano a París porque ambas palabras tiene significado parecido (ambas son ciudades importantes de europa); de la misma manera, la distancia entre las palabras “varón” y “mujer” sería similar a la distancia que existe entre “rey” y “reina”.</p>
<p>Son generadas a partir de grandes cuerpos de texto por algoritmos basados en redes neuronales, reducción de la dimensionalidad de matrices de co-ocurrencia y modelos probabilísticos.</p>
<p>Algunos enlaces de ayuda:</p>
<ul class="simple">
<li><p>https://en.wikipedia.org/wiki/Word2vec</p></li>
<li><p>https://github.com/aitoralmeida/spanish_word2vec</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Notebooks\3. Procesamiento del Lenguaje Natural"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../2.%20Web%20Scraping/Ejercicio_NUSO_web_scrappng.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Ejercicio: Web Scrapping para extraer información de un artículo</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../4.%20Segundo%20parcial%20Ejercicio%20tema%201%2C%202%20y%203/Prueba%20dos%20resulta%20por%20el%20profesor.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Ejercicio misceláneo: NLP, Web Scrapping</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>